{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8dBMKNHCGQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4d4b07-13d0-4df2-ff4e-1e16fd637fff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2640397119/2640397119 [00:58<00:00, 45449442.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/stl10_binary.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 98.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check the last digit of your roll number\n",
        "roll_number = 12204  #  roll number\n",
        "last_digit = roll_number % 3\n",
        "\n",
        "# Select dataset based on the last digit\n",
        "if last_digit == 0:\n",
        "    dataset_name = 'STL10'\n",
        "    train_data = datasets.STL10(root='./data', split='train', download=True, transform=transforms.ToTensor())\n",
        "    test_data = datasets.STL10(root='./data', split='test', download=True, transform=transforms.ToTensor())\n",
        "elif last_digit == 1:\n",
        "    dataset_name = 'SVHN'\n",
        "    train_data = datasets.SVHN(root='./data', split='train', download=True, transform=transforms.ToTensor())\n",
        "    test_data = datasets.SVHN(root='./data', split='test', download=True, transform=transforms.ToTensor())\n",
        "else:\n",
        "    dataset_name = 'FashionMNIST'\n",
        "    train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "    test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "# Define DataLoader\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "# Load pre-trained ResNet101 model\n",
        "model = models.resnet101(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10)  # 10 classes for classification\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizers\n",
        "optimizers = {\n",
        "    'Adam': optim.Adam(model.parameters(), lr=0.001),\n",
        "    'Adagrad': optim.Adagrad(model.parameters(), lr=0.001),\n",
        "    'RMSprop': optim.RMSprop(model.parameters(), lr=0.001)\n",
        "}\n",
        "\n",
        "# Training function\n",
        "def train_model(optimizer):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    avg_loss = train_loss / len(train_loader)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5  # Adjust epochs as needed\n",
        "train_loss_history = {optimizer_name: [] for optimizer_name in optimizers}\n",
        "train_accuracy_history = {optimizer_name: [] for optimizer_name in optimizers}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for optimizer_name, optimizer in optimizers.items():\n",
        "        train_loss, train_accuracy = train_model(optimizer)\n",
        "        train_loss_history[optimizer_name].append(train_loss)\n",
        "        train_accuracy_history[optimizer_name].append(train_accuracy)\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Optimizer: {optimizer_name}, '\n",
        "              f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
        "\n",
        "# Plot training curves\n",
        "plt.figure(figsize=(10, 5))\n",
        "for optimizer_name, loss_history in train_loss_history.items():\n",
        "    plt.plot(range(1, num_epochs + 1), loss_history, label=optimizer_name)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title(f'Training Loss Curve ({dataset_name})')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for optimizer_name, accuracy_history in train_accuracy_history.items():\n",
        "    plt.plot(range(1, num_epochs + 1), accuracy_history, label=optimizer_name)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Accuracy (%)')\n",
        "plt.title(f'Training Accuracy Curve ({dataset_name})')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Testing\n",
        "model.eval()\n",
        "top5_correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.topk(outputs, 5, dim=1)\n",
        "        predicted = predicted.t()\n",
        "        correct = predicted.eq(labels.view(1, -1).expand_as(predicted))\n",
        "        top5_correct += correct[:5].view(-1).float().sum(0)\n",
        "        total += labels.size(0)\n",
        "\n",
        "top5_accuracy = 100. * top5_correct / total\n",
        "print(f'Final Top-5 Test Accuracy: {top5_accuracy:.2f}%')\n"
		"print(f'Changes for assignment3')\n"
      ]
    }
  ]
}